[
  {
    "model": "human-baseline",
    "size": 86,
    "quantization": "f16",
    "score@1": null,
    "score@2": null,
    "l_hardcore": 80.11,
    "l_reject_rv": 100,
    "l_creative": 82,
    "l_long": 90,
    "l_acg": 61.45,
    "l_np": 48.7,

    "__meta__": {
      "extra_columns": [
        {
          "type": "weight",
          "name": "score@1",
          "weights": {
            "l_np": 2,
            "l_acg": 2,
            "l_hardcore": 1,
            "l_reject_rv": 0.5,
            "l_long": 1,
            "l_creative": 1.5
          }
        },
        {
          "type": "weight",
          "name": "score@2",
          "weights": {
            "l_np": 2,
            "l_acg": 1,
            "l_hardcore": 1,
            "l_reject_rv": 0,
            "l_long": 1,
            "l_creative": 0.5
          }
        }
      ]
    }
  },
  {
    "model": "fblgit/UNA-SimpleSmaug-34b-v1beta",
    "size": 34.4,
    "quantization": "q4_k_s",
    "l_hardcore": 46.855345911949684,
    "l_reject_rv": 13.888888888888884,
    "l_long": 65.34876655035588,
    "l_creative": 93.63333333333333,
    "l_np": 33.50431810412173,
    "l_acg": 35.555555555555564
  },
  {
    "model": "zetasepic/Qwen2.5-32B-Instruct-abliterated-v2",
    "size": 32.8,
    "quantization": "q3_k_m",
    "l_hardcore": 40.25157232704403,
    "l_reject_rv": 95,
    "l_long": 81.33868266953142,
    "l_creative": 88.10000000000001,
    "l_np": 47.47022721678598,
    "l_acg": 26.666666666666668
  },
  {
    "model": "AiCloser/Qwen2.5-32B-AGI",
    "size": 32.8,
    "quantization": "q4_k_s",
    "l_hardcore": 40.56603773584906,
    "l_reject_rv": 77.77777777777779,
    "l_long": 65.92327147357811,
    "l_creative": 89.56666666666668,
    "l_np": 31.42654857000855,
    "l_acg": 16.666666666666664
  },
  {
    "model": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-14B-Instruct-abliterated-v4",
    "size": 14.8,
    "quantization": "q4_k_m",
    "l_hardcore": 37.61,
    "l_reject_rv": 83
  },
  {
    "model": "TheDrummer/Star-Command-R-32B-v1",
    "size": 32.3,
    "quantization": "q3_k_m",
    "l_hardcore": 38.9937106918239,
    "l_reject_rv": 33.333333333333336,
    "l_long": 45.69829116930984,
    "l_creative": 85.53333333333335,
    "l_np": 25.551389009740653,
    "l_acg": 30.555555555555564
  },
  {
    "model": "anthracite-org/magnum-v4-27b",
    "size": 27.2,
    "quantization": "q4_k_m",
    "l_hardcore": 34.90566037735849,
    "l_reject_rv": 2.777777777777779,
    "l_long": 72.23146726419081,
    "l_creative": 93.03333333333332,
    "l_np": 30.992402338537005,
    "l_acg": 22.77777777777778
  },
  {
    "model": "huihui-ai/Qwen2.5-Coder-32B-Instruct-abliterated",
    "size": 32.8,
    "quantization": "q3_k_m",
    "l_hardcore": 33.54,
    "l_reject_rv": 14.000000000000002
  },
  {
    "model": "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2",
    "size": 7.62,
    "quantization": "q4_k_m",
    "l_hardcore": 32.70440251572327,
    "l_reject_rv": 88.88888888888889,
    "l_long": 85.45387312063986,
    "l_creative": 83.89999999999999,
    "l_np": 33.0904738597239,
    "l_acg": 13.333333333333334
  },
  {
    "model": "byroneverson/gemma-2-27b-it-abliterated",
    "size": 27.2,
    "quantization": "q4_k_m",
    "l_hardcore": 32,
    "l_long": 74.47939883518455,
    "l_creative": 70.80000000000001,
    "l_acg": 33.88,
    "l_np": 44.61233351093367,
    "l_reject_rv": 53
  },
  {
    "model": "IlyaGusev/saiga_nemo_12b",
    "size": 12.2,
    "quantization": "q4_k_m",
    "l_hardcore": 30.4,
    "l_reject_rv": 0
  },
  {
    "model": "huihui-ai/Qwen2.5-Coder-7B-Instruct-abliterated",
    "size": 7.62,
    "quantization": "q4_k_m",
    "l_hardcore": 29.78,
    "l_reject_rv": 78
  },
  {
    "model": "mlx-community/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2",
    "size": 7.62,
    "quantization": "q3_k_m",
    "l_hardcore": 29.7,
    "l_reject_rv": 92
  },
  {
    "model": "TheDrummer/Tiger-Gemma-9B-v3",
    "size": 9.24,
    "quantization": "q4_k_m",
    "l_hardcore": 29.46,
    "l_reject_rv": 0
  },
  {
    "model": "CohereForAI/aya-expanse-8b",
    "size": 8.03,
    "quantization": "q4_k_m",
    "l_hardcore": 26.01,
    "l_reject_rv": 8.399999999999997
  },
  {
    "model": "mlabonne/Hermes-3-Llama-3.1-8B-lorablated",
    "size": 8.03,
    "quantization": "q4_k_m",
    "l_hardcore": 25.7,
    "l_long": 47.34381178852976,
    "l_creative": 86.76666666666667,
    "l_acg": 3.88,
    "l_np": 25.99390454830381,
    "l_reject_rv": 50
  },
  {
    "model": "huihui-ai/Qwen2.5-3B-Instruct-abliterated",
    "size": 3.09,
    "quantization": "q6_k",
    "l_hardcore": 17.86,
    "l_reject_rv": 78
  },
  {
    "model": "IlyaGusev/gemma-2-2b-it-abliterated",
    "size": 2.61,
    "quantization": "q6_k",
    "l_hardcore": 16.9811320754717,
    "l_reject_rv": 77.77777777777779,
    "l_long": 71.73455397462284,
    "l_creative": 77.69999999999999,
    "l_np": 3.6463178335045257,
    "l_acg": 6.11111111111111
  },
  {
    "model": "natong19/Mistral-Nemo-Instruct-2407-abliterated",
    "size": 12.2,
    "quantization": "q4_k_m",
    "l_hardcore": 36.79245283018868,
    "l_reject_rv": 86.11111111111111,
    "l_long": 53.57792100798315,
    "l_creative": 86.53333333333335,
    "l_np": 31.212807411929678,
    "l_acg": 13.333333333333334
  },
  {
    "model": "nvidia/Nemotron-4-Mini-Hindi-4B-Instruct",
    "size": 4.19,
    "quantization": "q6_k",
    "l_hardcore": 14.42,
    "l_reject_rv": 23
  },
  {
    "model": "SicariusSicariiStuff/Phi-3.5-mini-instruct_Uncensored",
    "size": 3.82,
    "quantization": "q6_k",
    "l_hardcore": 3.44,
    "l_reject_rv": 91.7
  },
  {
    "model": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF",
    "size": 1.1,
    "quantization": "Q4_0",
    "l_hardcore": 2.2,
    "l_reject_rv": 0
  },
  {
    "model": "CohereForAI/c4ai-command-r-plus",
    "size": 104,
    "quantization": "iq1_m",
    "l_hardcore": 32,
    "l_reject_rv": 100
  },
  {
    "model": "fblgit/TheBeagle-v2beta-32B-MGS",
    "size": 32.8,
    "quantization": "q4_k_s",
    "l_hardcore": 41.82389937106918,
    "l_reject_rv": 11.111111111111116,
    "l_long": 77.84300480031881,
    "l_creative": 84.53333333333335,
    "l_np": 47.28889964957902,
    "l_acg": 24.444444444444446
  },
  {
    "model": "SaisExperiments/Gemma-2-2B-Opus-Instruct",
    "size": 2.61,
    "quantization": "q6_k",
    "l_hardcore": 19.12,
    "l_long": 54.598902412282484,
    "l_creative": 87.63333333333333,
    "l_acg": 6.11,
    "l_np": 12.43747843667888,
    "l_reject_rv": 0
  },
  {
    "model": "lenML/aya-expanse-8b-abliterated",
    "size": 8.03,
    "quantization": "q4_k_m",
    "l_hardcore": 25.391849529780565,
    "l_long": 73.36891621336788,
    "l_creative": 93.89999999999999,
    "l_acg": 13.88,
    "l_np": 0.7667032015154481,
    "l_reject_rv": 48
  },
  {
    "model": "w4r10ck/SOLAR-10.7B-Instruct-v1.0-uncensored",
    "size": 10.7,
    "quantization": "q4_k_m",
    "l_hardcore": 12.264150943396226,
    "l_reject_rv": 97.22222222222221,
    "l_long": 40.666693645177986,
    "l_creative": 97.06666666666666,
    "l_np": 30.229112020846028,
    "l_acg": 7.77777777777778
  },
  {
    "model": "AALF/gemma-2-27b-it-SimPO-37K-100steps",
    "size": 27.2,
    "quantization": "q4_k_s",
    "l_hardcore": 31.761006289308174,
    "l_reject_rv": 13.888888888888884,
    "l_long": 70.35036572891538,
    "l_creative": 92.06666666666666,
    "l_np": 44.1812805819529,
    "l_acg": 32.22222222222222
  },
  {
    "model": "Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24",
    "size": 12.2,
    "quantization": "q4_k_s",
    "l_hardcore": 32.288401253918494,
    "l_long": 70.07528015634581,
    "l_creative": 75.96666666666668,
    "l_reject_rv": 13.890000000000002
  },
  {
    "model": "Vikhrmodels/Vikhr-Qwen-2.5-0.5b-Instruct",
    "size": 0.494,
    "quantization": "q6_k",
    "l_hardcore": 14.420062695924765,
    "l_long": 47.70607331750326,
    "l_creative": 63.6,
    "l_acg": 0.55,
    "l_np": 0.01935321914181979,
    "l_reject_rv": 41.7
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v2-9B",
    "size": 9.24,
    "quantization": "q4_k_s",
    "l_hardcore": 25.705329153605017,
    "l_long": 58.17430575196378,
    "l_creative": 92.23333333333333,
    "l_acg": 22.22,
    "l_np": 30.63899690139084,
    "l_reject_rv": 38.9
  },
  {
    "model": "anthracite-org/magnum-v4-12b",
    "size": 12.2,
    "quantization": "q4_k_s",
    "l_hardcore": 40.75235109717868,
    "l_long": 45.684937668977135,
    "l_creative": 75.43333333333332,
    "l_acg": 15.55,
    "l_np": 27.99894982188303,
    "l_reject_rv": 0
  },
  {
    "model": "nbeerbower/Qwen2.5-Gutenberg-Doppel-14B",
    "size": 14.8,
    "quantization": "q4_k_s",
    "l_hardcore": 37.61755485893417,
    "l_long": 61.82586432518972,
    "l_creative": 93.10000000000001,
    "l_acg": 28.33,
    "l_reject_rv": 6.000000000000005
  },
  {
    "model": "IlyaGusev/saiga_nemo_12b-v3",
    "size": 12.2,
    "quantization": "q4_k_s",
    "l_hardcore": 31.974921630094045,
    "l_long": 51.41011604945617,
    "l_creative": 93.16666666666667,
    "l_acg": 7.77,
    "l_np": 30.246717820430398,
    "l_reject_rv": 0
  },
  {
    "model": "DavidAU/L3-Dark_Mistress-The_Guilty_Pen-Uncensored-17.4B-GGUF",
    "size": 17.4,
    "quantization": "q4_k_m",
    "l_hardcore": 12.225705329153605,
    "l_long": 46.52916207497656,
    "l_creative": 87,
    "l_acg": 4.44,
    "l_reject_rv": 58.33333333333333
  },
  {
    "model": "CohereForAI/c4ai-command-r-08-2024",
    "size": 32.3,
    "quantization": "q4_k_s",
    "l_hardcore": 36.36,
    "l_long": 66.02860674582767,
    "l_creative": 92.09999999999998,
    "l_acg": 27.77,
    "l_np": 22.37767346013845,
    "l_reject_rv": 44.99999999999999
  },
  {
    "model": "grok-beta",
    "size": 600,
    "quantization": "f16",
    "l_hardcore": 50.470219435736674,
    "l_long": 74.74067294475033,
    "l_creative": 90.13333333333333,
    "l_acg": 14.44,
    "l_np": 45.86,
    "l_reject_rv": 0
  },
  {
    "model": "anthracite-org/magnum-v4-9b",
    "size": 9.24,
    "quantization": "q4_k_s",
    "l_hardcore": 34.90566037735849,
    "l_long": 54.97595506523796,
    "l_creative": 81.13333333333334,
    "l_acg": 20.555555555555554,
    "l_np": 27.04019756178699,
    "l_reject_rv": 11.111111111111116
  },
  {
    "model": "anthracite-org/magnum-v4-22b",
    "size": 22.2,
    "quantization": "q4_k_s",
    "l_hardcore": 27.67295597484277,
    "l_long": 56.87408151760139,
    "l_creative": 84.93333333333334,
    "l_acg": 3.88888888888889,
    "l_np": 16.781240945173654,
    "l_reject_rv": 2.777777777777779
  },
  {
    "model": "TinyLlama/TinyLlama_v1.1",
    "size": 1.1,
    "quantization": "q6_k",
    "l_hardcore": 1.257861635220126,
    "l_long": 0,
    "l_creative": 0,
    "l_acg": -1.6666666666666667,
    "l_np": 0,
    "l_reject_rv": 34
  },
  {
    "model": "anthracite-org/magnum-v4-27b",
    "size": 27.2,
    "quantization": "q4_k_s",
    "l_hardcore": 33.64779874213836,
    "l_long": 59.90044443835702,
    "l_creative": 91.89999999999999,
    "l_acg": 27.22222222222222,
    "l_np": 31.240704690874267,
    "l_reject_rv": 12
  },
  {
    "model": "CohereForAI/aya-expanse-32b",
    "size": 32.2,
    "quantization": "q4_k_s",
    "l_hardcore": 36.477987421383645,
    "l_long": 70.99025147049771,
    "l_creative": 90.33333333333333,
    "l_np": 22.999517173563426,
    "l_acg": 16.666666666666664,
    "l_reject_rv": 5.555555555555558
  },
  {
    "model": "Qwen/QwQ-32B-Preview",
    "size": 32.2,
    "quantization": "q4_k_s",
    "l_hardcore": 41.82389937106918,
    "l_long": 31.91180514636126,
    "l_creative": 84.60000000000001,
    "l_np": 42.0793789378002,
    "l_acg": 22.77777777777778,
    "l_reject_rv": 5.555555555555558
  },
  {
    "model": "byroneverson/internlm2_5-20b-chat-abliterated",
    "size": 19.9,
    "quantization": "q4_k_m",
    "l_hardcore": 35.53459119496855,
    "l_long": 40.513706893174295,
    "l_creative": 100,
    "l_np": 25.397696415172987,
    "l_acg": 3.3333333333333384,
    "l_reject_rv": 19.444444444444443
  },
  {
    "model": "allknowingroger/MixTAO-19B-pass",
    "size": 19.2,
    "quantization": "q4_k_m",
    "l_hardcore": 8.80503144654088,
    "l_reject_rv": 63.888888888888886,
    "l_long": 49.16178347351046,
    "l_creative": 91.39999999999999,
    "l_np": 18.75413779958315,
    "l_acg": 6.666666666666667
  },
  {
    "model": "IlyaGusev/gemma-2-9b-it-abliterated",
    "size": 9.24,
    "quantization": "q4_k_m",
    "l_hardcore": 27.358490566037734,
    "l_reject_rv": 91.66666666666666,
    "l_long": 71.72644889202607,
    "l_creative": 65.5,
    "l_np": 35.01038282549306,
    "l_acg": 20.555555555555554
  },
  {
    "model": "Lambent/qwen2.5-reinstruct-alternate-lumen-14B",
    "size": 14.8,
    "quantization": "q4_k_m",
    "l_hardcore": 37.735849056603776,
    "l_reject_rv": 11.111111111111116,
    "l_long": 63.16200390494302,
    "l_creative": 92.66666666666667,
    "l_np": 40.35779931073713,
    "l_acg": 24.444444444444446
  },
  {
    "model": "AIDC-AI/Marco-o1",
    "size": 7.62,
    "quantization": "q4_k_m",
    "l_hardcore": 33.0188679245283,
    "l_reject_rv": 47.22222222222222,
    "l_long": 77.27909119285796,
    "l_creative": 92.06666666666666,
    "l_np": 15.96877835480458,
    "l_acg": 15
  },
  {
    "model": "v000000/Qwen2.5-14B-Gutenberg-Instruct-Slerpeno",
    "size": 14.8,
    "quantization": "q4_k_m",
    "l_hardcore": 39.308176100628934,
    "l_reject_rv": 5.555555555555558,
    "l_long": 64.99438632818833,
    "l_creative": 93.43333333333334,
    "l_np": 19.981867310239668,
    "l_acg": 25.555555555555554
  },
  {
    "model": "huihui-ai/Qwen2.5-Coder-3B-Instruct-abliterated",
    "size": 3.09,
    "quantization": "q6_k",
    "l_hardcore": 26.729559748427672,
    "l_reject_rv": 88.88888888888889,
    "l_long": 51.507341396879646,
    "l_creative": 99.5,
    "l_np": 11.185295848865362,
    "l_acg": 2.7777777777777763
  },
  {
    "model": "sam-paech/Darkest-muse-v1",
    "size": 10.2,
    "quantization": "q4_k_m",
    "l_hardcore": 28.930817610062892,
    "l_reject_rv": 5.555555555555558,
    "l_long": 84.20226776322998,
    "l_creative": 57.70000000000001,
    "l_np": 22.06298577700235,
    "l_acg": 24.444444444444446
  },
  {
    "model": "sam-paech/Quill-v1",
    "size": 9.24,
    "quantization": "q4_k_m",
    "l_hardcore": 29.559748427672954,
    "l_reject_rv": 5.555555555555558,
    "l_long": 79.84996021557392,
    "l_creative": 48.06666666666666,
    "l_np": 36.715514004623046,
    "l_acg": 31.666666666666664
  },
  {
    "model": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B-v2",
    "size": 12.2,
    "quantization": "q4_k_m",
    "l_hardcore": 38.36477987421384,
    "l_reject_rv": 41.666666666666664,
    "l_long": 56.364619393480446,
    "l_creative": 93.43333333333332,
    "l_np": 36.839942555427044,
    "l_acg": 8.333333333333332
  },
  {
    "model": "Nexusflow/Athene-70B",
    "size": 70.6,
    "quantization": "q2_xxs",
    "l_hardcore": 26.10062893081761,
    "l_reject_rv": 13.888888888888884,
    "l_long": 49.7593172283244,
    "l_creative": 90.8,
    "l_np": 39.5366857083096,
    "l_acg": 13.888888888888895
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5-Qwen-32b",
    "size": 32.8,
    "quantization": "q4_k_m",
    "l_hardcore": 40.56603773584906,
    "l_reject_rv": 8.333333333333337,
    "l_long": 71.1161246384246,
    "l_creative": 81.99999999999999,
    "l_np": 44.81176061326696,
    "l_acg": 27.22222222222222
  },
  {
    "model": "infly/OpenCoder-1.5B-Instruct",
    "size": 1.91,
    "quantization": "q6_k",
    "l_hardcore": 10.377358490566039,
    "l_reject_rv": 47.22222222222222,
    "l_long": 22.039223509564277,
    "l_creative": 93,
    "l_np": 1.8257426752115329,
    "l_acg": 8.333333333333332
  },
  {
    "model": "TheDrummer/UnslopNemo-12B-v4.1-GGUF",
    "size": 12.2,
    "quantization": "q4_k_m",
    "l_hardcore": 36.79245283018868,
    "l_reject_rv": 8.333333333333337,
    "l_long": 44.17612763998968,
    "l_creative": 80.76666666666667,
    "l_np": 30.812809903051008,
    "l_acg": 13.888888888888895
  },
  {
    "model": "TheDrummer/Cydonia-22B-v1.3-GGUF",
    "size": 22.2,
    "quantization": "q4_k_m",
    "l_hardcore": 21.069182389937108,
    "l_reject_rv": 13.888888888888884,
    "l_long": 54.36037593072415,
    "l_creative": 92.89999999999999,
    "l_np": 18.291433113383988,
    "l_acg": 7.222222222222219
  },
  {
    "model": "anthracite-org/magnum-v3-27b-kto",
    "size": 27.2,
    "quantization": "q4_k_m",
    "l_hardcore": 31.446540880503143,
    "l_reject_rv": 11.111111111111116,
    "l_long": 48.86242232233042,
    "l_creative": 84.73333333333333,
    "l_np": 29.1993525163826,
    "l_acg": 13.333333333333334
  },
  {
    "model": "infly/OpenCoder-8B-Instruct",
    "size": 7.77,
    "quantization": "q4_k_m",
    "l_hardcore": 28.930817610062892,
    "l_reject_rv": 25,
    "l_long": 34.882885253744064,
    "l_creative": 99.5,
    "l_np": 15.075652336756884,
    "l_acg": 3.88888888888889
  },
  {
    "model": "princeton-nlp/gemma-2-9b-it-SimPO",
    "size": 9.24,
    "quantization": "q4_k_m",
    "l_hardcore": 28.930817610062892,
    "l_reject_rv": 13.888888888888884,
    "l_long": 71.68007401372978,
    "l_creative": 87.56666666666666,
    "l_np": 30.826057745106834,
    "l_acg": 22.22222222222223
  },
  {
    "model": "mlabonne/Llama-3.1-70B-Instruct-lorablated",
    "size": 70.6,
    "quantization": "q2_xxs",
    "l_hardcore": 26.729559748427672,
    "l_reject_rv": 47.22222222222222,
    "l_long": 50.432344958214145,
    "l_creative": 79.39999999999999,
    "l_np": 35.8654996920801,
    "l_acg": 17.222222222222218
  },
  {
    "model": "CausalLM/34b-beta",
    "size": 34.4,
    "quantization": "q4_k_s",
    "l_hardcore": 48.42767295597484,
    "l_reject_rv": 16.666666666666664,
    "l_long": 58.94673831637018,
    "l_creative": 79.56666666666666,
    "l_np": 24.35017238189056,
    "l_acg": 34.444444444444436
  },
  {
    "model": "oxyapi/oxy-1-small",
    "size": 14.8,
    "quantization": "q4_k_m",
    "l_hardcore": 35.53459119496855,
    "l_reject_rv": 58.33333333333333,
    "l_long": 61.03737974015621,
    "l_creative": 85.96666666666665,
    "l_np": 20.032323741667636,
    "l_acg": 13.888888888888895
  },
  {
    "model": "huihui-ai/Qwen2.5-14B-Instruct-abliterated-v2",
    "size": 14.8,
    "quantization": "q4_k_m",
    "l_hardcore": 37.735849056603776,
    "l_reject_rv": 88.88888888888889,
    "l_long": 75.77191174183017,
    "l_creative": 92.8,
    "l_np": 20.874359658709967,
    "l_acg": 27.22222222222222
  },
  {
    "model": "MarinaraSpaghetti/NemoMix-Unleashed-12B",
    "size": 12.2,
    "quantization": "q4_k_m",
    "l_hardcore": 40.88050314465409,
    "l_reject_rv": 13.888888888888884,
    "l_long": 49.09862602434891,
    "l_creative": 87.13333333333334,
    "l_np": 28.971311853641723,
    "l_acg": 14.444444444444448
  },
  {
    "model": "deepseek-chat",
    "size": 236,
    "quantization": "f16",
    "l_hardcore": 55.9748427672956,
    "l_reject_rv": 22.22222222222222,
    "l_long": 75.08873641755063,
    "l_creative": 88.93333333333334,
    "l_np": 1.3510745736128351,
    "l_acg": 53.8888888888889
  },
  {
    "model": "mlabonne/Hermes-3-Llama-3.1-70B-lorablated",
    "size": 70.6,
    "quantization": "q2_xxs",
    "l_hardcore": 27.044025157232703,
    "l_reject_rv": 69.44444444444444,
    "l_long": 50.65233151599157,
    "l_creative": 78.73333333333335,
    "l_np": 18.3632387097112,
    "l_acg": 9.444444444444446
  },
  {
    "model": "meta-llama/Llama-3.3-70B-Instruct",
    "size": 70.6,
    "quantization": "q2_xxs",
    "l_hardcore": 27.9874213836478,
    "l_reject_rv": 19.444444444444443,
    "l_long": 59.51393571689076,
    "l_creative": 82.66666666666667,
    "l_np": 42.1832992146105,
    "l_acg": 9.444444444444446
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Korean-Superb-27B",
    "size": 27.2,
    "quantization": "q4_k_m",
    "l_hardcore": 28.61635220125786,
    "l_reject_rv": 11.111111111111116,
    "l_long": 72.42349767600757,
    "l_creative": 84.46666666666665,
    "l_np": 36.79172276159477,
    "l_acg": 26.111111111111114
  },
  {
    "model": "NeverSleep/Lumimaid-v0.2-12B",
    "size": 12.2,
    "quantization": "q4_k_m",
    "l_hardcore": 43.39622641509434,
    "l_reject_rv": 75,
    "l_long": 36.48928967938965,
    "l_creative": 81.76666666666667,
    "l_np": 15.265753069021581,
    "l_acg": 12.77777777777778
  },
  {
    "model": "nbeerbower/mistral-nemo-bophades-12B",
    "size": 12.2,
    "quantization": "q4_k_m",
    "l_hardcore": 35.53459119496855,
    "l_reject_rv": 52.77777777777778,
    "l_long": 51.617711093815245,
    "l_creative": 90.76666666666667,
    "l_np": 24.665146931004532,
    "l_acg": 11.111111111111105
  },
  {
    "model": "nbeerbower/mistral-nemo-wissenschaft-12B",
    "size": 12.2,
    "quantization": "q4_k_m",
    "l_hardcore": 36.16352201257861,
    "l_reject_rv": 19.444444444444443,
    "l_long": 44.78966824050486,
    "l_creative": 85.10000000000001,
    "l_np": 29.409190253650912,
    "l_acg": 19.44444444444444
  },
  {
    "model": "matteogeniaccio/phi-4",
    "size": 14.7,
    "quantization": "q4_k_m",
    "l_hardcore": 36.477987421383645,
    "l_reject_rv": 11.111111111111116,
    "l_long": 46.48753342592057,
    "l_creative": 83.06666666666666,
    "l_np": 30.274032465285956,
    "l_acg": 9.444444444444446
  },
  {
    "model": "nbeerbower/Mistral-Small-Drummer-22B",
    "size": 22.2,
    "quantization": "q4_k_m",
    "l_hardcore": 23.58490566037736,
    "l_reject_rv": 13.888888888888884,
    "l_long": 63.3918852516451,
    "l_creative": 89.7,
    "l_np": 23.772345717016602,
    "l_acg": 8.888888888888886
  },
  {
    "model": "byroneverson/Mistral-Small-Instruct-2409-abliterated",
    "size": 22.2,
    "quantization": "q4_k_m",
    "l_hardcore": 23.58490566037736,
    "l_reject_rv": 77.77777777777779,
    "l_long": 59.35205245271774,
    "l_creative": 91.93333333333334,
    "l_np": 16.19664132391164,
    "l_acg": 6.666666666666667
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-9B",
    "size": 10.2,
    "quantization": "q4_k_m",
    "l_hardcore": 29.559748427672954,
    "l_reject_rv": 5.555555555555558,
    "l_long": 77.05084714180452,
    "l_creative": 77.53333333333335,
    "l_np": 28.710913232166913,
    "l_acg": 25
  },
  {
    "model": "CultriX/Qwen2.5-14B-Wernicke",
    "size": 14.8,
    "quantization": "q4_k_m",
    "l_hardcore": 37.42138364779874,
    "l_reject_rv": 5.555555555555558,
    "l_long": 58.309175128552006,
    "l_creative": 90.86666666666667,
    "l_np": 20.194583036193002,
    "l_acg": 24.444444444444446
  },
  {
    "model": "grok-2-1212",
    "size": 600,
    "quantization": "f16",
    "l_hardcore": 50,
    "l_reject_rv": 33.333333333333336,
    "l_long": 75.1439344687903,
    "l_creative": 78.43333333333334,
    "l_np": 46.26982932694913,
    "l_acg": 15.555555555555554
  },
  {
    "model": "ifable/gemma-2-Ifable-9B",
    "size": 9.24,
    "quantization": "q4_k_m",
    "l_hardcore": 29.874213836477985,
    "l_reject_rv": 11.111111111111116,
    "l_long": 68.81987591847233,
    "l_creative": 89.86666666666667,
    "l_np": 25.049316500466524,
    "l_acg": 26.111111111111114
  },
  {
    "model": "huihui-ai/QwQ-32B-Preview-abliterated",
    "size": 32.2,
    "quantization": "q4_k_s",
    "l_hardcore": 33.33333333333333,
    "l_reject_rv": 80.55555555555556,
    "l_long": 53.06538550343251,
    "l_creative": 41.366666666666674,
    "l_np": 40.55531953225462,
    "l_acg": 26.111111111111114
  },
  {
    "model": "DeepSeek-V3",
    "size": 685,
    "quantization": "fp16",
    "l_hardcore": 54.40251572327044,
    "l_reject_rv": 25,
    "l_long": 76.25566226180744,
    "l_creative": 89.63333333333334,
    "l_np": 43.50797604186768,
    "l_acg": 37.222222222222214
  }
]
